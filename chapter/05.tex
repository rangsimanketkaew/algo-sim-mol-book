% LaTeX source for ``Algorithms for Computer Simulation of Molecular Systems''
% Copyright (c) 2023 รังสิมันต์ เกษแก้ว (Rangsiman Ketkaew).

% License: Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)
% https://creativecommons.org/licenses/by-nc-nd/4.0/

\chapter{การคำนวณวิทยาศาสตร์สมรรถนะสูง}
\label{ch:high_perf_comp}

%----------------------------------------
\section{ทำไมต้อง High-Performance Computing ?}
%----------------------------------------

%----------------------------------------
\section{ทำไมต้องคำนวณแบบขนาน (Parallel Computing) ?}
%----------------------------------------

%----------------------------------------
\section{ทักษะและเครื่องมือสำหรับการเขียนโปรแกรมสำหรับ HPC}
%----------------------------------------

- Architecture
  - Memory management
  - Threading, multithreading
  - Block

- Parallel computing (SPMD)
  - Shared memory: OpenMP
  - Distributed memory: MPI
    - Implementations: OpenMPI, Intel MPI, MVAPICH

- Intel ecosystem
  - OpenMP compiler: icc, ifort
  - MPI compiler: mpicc, mpiicc (for Intel C compiler), mpicxx (for C++), mpiifort (for Fortran)

- Cloud computing (bonus)

- Server and database

- Networking

Essential skills for coding GPU

- Intermediate/advanced C or C++ skills

- Programming model: Kernels, thread hierarchy, memory hierarchy, heterogeneous hierarchy, asynchronous SIMT

- CUDA
  - Understand CUDA operation:
    1. Declare and allocate host and device memory.
    2. Initialize host data.
    3. Transfer data from the host to the device.
    4. Execute one or more kernels.
    5. Transfer results from the device to the host.
  - CUDA C and CUDA C++ API
  - Compiler: nvcc

%----------------------------------------
\section{Matrix Diagonalization}
%----------------------------------------

ในหัวข้อนี้ผู้อ่านจะได้ศึกษาการทำให้เกิดเมทริกซ์รูปทแยงหรือ Matrix Diagonalization (ผมขอเรียกสั้น ๆ ว่า MatDiag เพื่อความสะดวก) 
ในการคำนวณแบบขนาน (Parallel Computing) สำหรับการคำนวณทางเคมีควอนตัม โดย MatDiag คือการดำเนินการ (Operation) 
ทางพีชคณิตเชิงเส้นแบบหนึ่งซึ่งถูกใช้อย่างแพร่หลายโดยเฉพาะในงานวิจัยด้านการคำนวณทางวิทยาศาสตร์ แน่นอนว่าโปรแกรมทางเคมีควอนตัมนั้นก็ใช้ 
MatDiag เยอะมาก ๆ ซึ่งมีความซับซ้อนเชิงการคำนวณอยู่ที่ $O(n^3)$ ทำให้เกิดปัญหาคอขวดและทำให้การคำนวณของระบบที่มีขนาดใหญ่นั้นช้ามาก ๆ 
เพื่อแก้ปัญหาดังกล่าวจึงได้มีการพัฒนาเทคนิคและไลบรารี่ที่จะเข้ามาช่วยเราในการทำ MatDiag ได้แบบขนาดหรือ Parallel ซึ่งช่วยให้การทำ 
MatDiag เร็วขึ้นถึง 50\% เลยทีเดียว เริ่มต้นเรามีเมทริกซ์ที่มีขนาดใหญ่และสมาชิกส่วนใหญ่ของเมทริกซ์นั้นมีค่าไม่เท่ากับ 0 (Nonzero Elements) 
ซึ่งเราจะเรียกเมทริกซ์ประเภทนี้ว่าเมทริกซ์แบบเต็ม (Full Matrix) หรือเมทริกซ์แบบแน่น (Dense Matrix) ก็ได้ โดยเราสามารถแทน Dense 
Matrix ได้โดยใช้รูปแบบที่เรียกว่า Block Cyclic ในการทำการคำนวณแบบขนานด้วยวิธี Message-passing Interface (MPI) ซึ่งเป็นการ%
กำหนดการกระจาย Dense Matrix ไปยังหน่วยประมวลผล (Processor) แต่ละตัวของเครื่องคำนวณ (Compute Node) ในคลัสเตอร์คอมพิวเตอร์ 



ให้ดูที่ภาพแรกก่อนซึ่งเป็นการเปรียบเทียบการกระจายแบบ \enquote{Cyclic} และแบบ \enquote{Block} สำหรับเวกเตอร์ 1 มิติและเมทริกซ์ 
2 มิติ (ภาพด้านล่างผมคัดลอกมาจาก Tutorial \enquote{Introduction to Parallel} ของ Blaise Barney แห่งสถาบัน LLNL) 
โดยสีแต่ละสีของแต่ละช่องนั้นจะเป็นการบ่งบอกถึง Processor ที่ต่างกัน และแต่ละ Segment นั้นจะบ่งบอกถึงสัดส่วน (portion) ของ Dense 
Matrix ที่ถูกกำหนดและแบ่งเข้าไปใน Local Memory ของแต่ละ Processor สำหรับการแยกออกเป็นส่วน ๆ แบบหมุนวน (Cyclic Decomposition) 
ของเมทริกซ์นั้นสามารถทำได้คือเราจะทำการ Distribute แต่ละแถวหรือแต่ละคอลัมน์ไปยัง Processor ที่แตกต่างกัน (เราอาจจะแบ่งเป็นทีละคู่ก็ได้ 
เช่น แบ่งทุก ๆ 2 แถว) ในทางตรงข้ามนั้น วิธีการแบ่งแบบ Block Representation นั้นจะเป็นการแยกเมทริกซ์ออกเป็นเมทริกซ์ย่อย ๆ จำนวน 
$N$ เมทริกซ์ (เรียกว่า Submatrices ก็ได้) โดยไม่สนใจว่าขนาดของแต่ละ Block นั้นจะต้องมีขนาดที่เท่ากัน ซึ่งแต่ละ Submatrix นั้นจะถูก%
ส่งต่อไปยัง Processor แต่ละตัว สรุปคือการแบ่งแบบ Cyclic นั้นเป็นการนำการแบ่งแบบ Block มาทำซ้ำ ๆ กันไปแบบละเอียดกว่า ซึ่งจะทำให้%
เราได้ Block ที่มากกว่า

แล้วข้อดีหรือข้อเสียของทั้งสองวิธีนี้คืออะไร? เราจะเห็นได้ว่า Cyclic Distribution นั้นจะเหมาะกว่าการกระจายเมทริกซ์แบบเท่า ๆ กัน (evenly) 
แต่ว่าจะมีการจัดการเมทริกซ์ที่ทำได้แย่กว่าเพราะว่าจะต้องมีการสื่อสาร (Communication) ระหว่าง Processor และระหว่าง Compute Node 
ในการส่งต่อข้อมูลของ Matrix Element ที่ถูกคำนวณด้วย Processor ที่อยู่ใกล้กันซึ่งในทางตรงกันข้ามนั้นการ Communication ใน Block 
Representation Matrix นั้นจะทำได้ดีกว่าเพราะว่ามันมีการแบ่งแบบต่อเนื่องบนหน่วยความจำ แต่ว่าถ้าหากว่า Matrix ของเราเป็นแบบ Sparse 
Matrix หรือเมทริกซ์ที่มีสมาชิกส่วนใหญ่เป็น 0 นั้นก็อาจจะเกิดปัญหาเช่น Load Balancing ได้ 

เพื่อรวมข้อดีของทั้งสองวิธีไว้จึงได้มีการแบ่งแบบ Block Cyclic Distribution ซึ่งก็คือเป็นการแยกเมทริกซ์ออกเป็น Block เล็ก ๆ แล้วก็ทำการกระจาย 
Blocks เหล่านี้แบบหมุนวน (Cyclically) ไปยัง Processors ทุกตัว โดยให้ดูตัวอย่างของ Block Cyclic Distribution ตามภาพที่ 2
สำหรับวิธีการแบ่งที่มีประสิทธิภาพที่สุดนั้นก็คือจำนวนของ Block ที่ถูกแบ่งออกมานั้นนั้นจะต้องเท่ากับจำนวนของ Processors 
(หมายความว่ามีมิติเท่ากัน $N_{\text{row}} \times N_{\text{col}}$) 
โดย N คือจำนวน Processors ซึ่งตามภาพที่สองนั้นเราจะเห็นได้ว่า Block ที่มีสีเหมือนกันนั้นคือถูกคำนวณบน Processor เดียวกัน (ดู Local View) 
และขนาดของแต่ละ Block ควรจะต้องเท่ากันด้วย ส่วนภาพที่ 3 นั้นแถมให้ครับ ซึ่งก็เป็นอีกตัวอย่างของการแยกเมทริกซ์ออกเป็นส่วน ๆ (Decomposition) 
แบบ Block Cyclic Distribution

%----------------------------------------
\section{การวัดประสิทธิภาพไลบรารี่สำหรับ Matrix Diagonalization}
%----------------------------------------

เราจะมาศึกษาการวัดประสิทธิภาพของไลบรารี่ ScaLAPACK กับ ELPA ซึ่งทั้งสองตัวนี้เป็นไลบรารี่สำหรับการทำ MatDiag แบบขนานซึ่งได้รับความนิยม%
ในการนำมาใช้ในการเขียนโปรแกรมที่รันบนซุปเปอร์คอมพิวเตอร์ เช่น โปรแกรมสำหรับการทำงานวิจัยด้านวิทยาศาสตร์ โดยเราได้ศึกษากันไปแล้วว่า%
ถ้าหากเรามี Dense Matrix A ที่ถูกกระจายหรือแบ่งไปคำนวณบน Processors แต่ละตัวด้วยวิธี MPI โดยการใช้ Block Cyclic Distribution 
สิ่งที่เรามักจะทำกันต่อจากนั้นก็คือการ Diagonalize ซึ่งเราต้องพยายามทำให้มัน Efficient ที่สุดโดยการทำ Diagonalization นั้นคือการหา%
คำตอบของปัญหาค่าไอเกน (Eigenvalue Problem) ดังต่อไปนี้ AX = XL โดยที่ X คือเมทริกซ์ที่บรรจุ Eigenvector ของ A ไว้ ส่วน L 
นั้นคือเมทริกซ์ที่บรรจุค่า Eigenvalue ซึ่งเมทริกซ์ L นี้เองที่เราจะต้องมาทำการหาเพราะมันเป็น Diagonal เมทริกซ์จริง ๆ ของ A 

ในไลบรารี่ ScaLAPACK นั้นมีอัลกอริทึม 3 ตัวที่เราสามารถนำมาใช้ในการทำ Diagonalize Matrix ที่เป็น Real Symmetry Matrix 
(เมทริกซ์ที่มีความสมมาตรและมีเพียงแค่ค่าจริงเป็นสมาชิกเท่านั้น) นั่นคือ p?syevd, p?syevx, และ p?syevr โดยที่ ? นั้นแทนด้วยค่าที่บ่งบอก%
ถึงประเภทของข้อมูลในเมทริกซ์ เช่น ถ้าแทน ? ด้วย d จะหมายถึงเมทริกซ์นั้นเก็บข้อมูลประเภท Double Precision
โดยทั้งสามอัลกอริทึมนี้ก็จะใช้วิธีที่แตกต่างกันไป เช่น syevd จะใช้วิธีแบ่งแยกและเอาชนะ (Divide and Conquer) ซึ่งผลการทดสอบที่แสดง%
ด้านล่างนั้นได้มาจากการใช้ p?syevd นั่นเองครับ โดยสรุปสั้น ๆ คือวิธี Divide and Conquer นั้นจะเริ่มด้วยการทำการลดรูปเมทริกซ์ (Reduction) 
A ให้เป็น Tridiagonal Matrix ก่อนโดยใช้การแปลง Householder หลังจากนั้นก็ทำการหา Tridiagonal Eigenvalue ด้วยอัลกอริทึม 
Divide and Conquer แล้วก็ทำการแปลงย้อนกลับไปให้ได้เป็น Eigenvector ออกมา

ตามที่ได้อธิบาย p?syevd ของไลบรารี่ ScaLAPACK ไปแล้วนั้น ลำดับต่อไปคือไลบรารี่ยอดฮิตอีกตัวที่ได้รับความนิยมในการนำมาใช้ในโปรแกรมทาง%
เคมีควอนตัมหลายตัวด้วยกัน เช่น NWChem และ CP2K นั่นก็คือไลบรารี่ ELPA จริง ๆ แล้ว ELPA นั้นเอาอัลกอริทึมใน ScaLAPACK มาปรับปรุง%
อีกทีนึงเพื่อให้มีประสิทธิภาพมากขึ้น โดยจะใช้เทคนิค Direction Transformation ของ Tridiagonal Form ซึ่งก็มีความซับซ้อนพอสมควร 
เอาเป็นว่าทั้ง ScaLAPACK กับ ELPA ก็สามารถนำมาใช้ได้ทั้งคู่ แล้วก็ Interface นั้นมีความคล้ายคลึงกันมาก สิ่งที่แตกต่างอีกอย่างหนึ่งก็คือ ELPA 
นั้นมีความ General มากกว่าตรงที่สามารถใช้กับ Fortran Kernel ได้บนหลากหลายสถาปัตยกรรมมากกว่า เช่น ถ้า Kernel ของ CPU เป็นแบบใหม่ ๆ 
เช่น AVX, AVX2, หรือ AVX-512 นั้น ELPA ก็จะรองรับ คราวนี้เรามาดูการทำ Benchmark หรือการวัดประสิทธิภาพของไลบรารี่ทั้งคู่นี้กัน
ปกติแล้วการทำ MatDiag นั้นจะขึ้นอยู่กับปัจจัยหลายตัว โดยหลัก ๆ แล้วมีดังนี้

\begin{itemize}
    \item ขนาดของ Matrix
    
    \item โครงสร้างของ Matrix
    
    \item จำนวน Processors ของเครื่องที่ใช้ในการรันหรือคำนวณ Diagonalization
    
    \item ขนาดของ MPI Block Size สำหรับ Matrix
    
    \item อัลกอริทึมที่ใช้ในการทำ Diagonalization
\end{itemize}

สำหรับตัวอย่างที่เราจะมารันทดสอบ Benchmark กันนัั้นก็คือเมทริกซ์จตุรัสขนาด $5888 \times 5888$ กับขนาด $13034 \times 13034$ 
ตามลำดับ โดยใช้โปรแกรม CP2K (โปรแกรมทางเคมีควอนตัม) ซึ่งจริง ๆ แล้วก็คือระบบที่เป็นโมเลกุลน้ำ (Water Cluster) 128 โมเลกุลนั่นเอง
สำหรับเครื่องซุปเปอร์คอมพิวเตอร์ที่ใช้ในการทดสอบนั้นคือ Cray XC40 ซึ่งมีสเปคคือแต่ละโหนดนั้นจะมี 12-core Intel Xeon E5-2690v3 Processors 
ทั้งหมด 2 ตัว และมี Memory คือ 64 GB (DDR4) สำหรับผลการทดสอบนั้นก็ดูตามภาพด้านล่างได้เลย แกน y คือประสิทธิภาพที่ได้ส่วนแกน $x$ 
นั้นคือจำนวนของ Node ของ Cray XC40 โดย SL คือ ScaLAPACK, ส่วน QR นั้นคือเทคนิค Decomposition แบบหนึ่งที่เราเอาเข้ามาช่วยใน%
การเพิ่มประสิทธิภาพการทำ Diagonalization ของ ELPA นั่นเอง ภาพด้านซ้ายนั้นคือระบบที่เมทริกซ์ขนาดใหญ่ส่วนด้านขวาเมทริกซ์ขนาดเล็ก
สรุปคือจากการทดสอบนั้นก็คือ ELPA ชนะขาดลอยในการทำ Diagonalization แบบขนานด้วย MPI ซึ่ง ELPA ทำประสิทธิภาพได้ดีกว่า SL 
ประมาณ 60-80\% เลยทีเดียว

%----------------------------------------
\section{การประยุกต์ใช้ Matrix Diagonalization}
%----------------------------------------

หนึ่งในการประยุกต์ใช้ Matrix Diagonalization ในโปรแกรมเคมีเชิงคำนวณก็คือการคำนวณพลังงานของออร์บิทัล (Orbital Energies) 
ซึ่งเป็นเทอมที่สำคัญมาก ๆ ในทางเคมีเพราะว่าเป็นตัวที่เราจะนำมาใช้ในการศึกษาโมเลกุล โดยหลาย ๆ คนที่เคยวิชาเคมีอินทรีย์เชิงฟิสิกส์มานั้นก็น่า%
จะเคยผ่านการใช้ Huckel Model Theory ในการคำนวณหาพลังงานของออร์บิทัลของโมเลกุลเคมีอินทรีย์ (สารประกอบไฮโดรคาร์บอน) แบบง่าย ๆ 
กันมาแล้ว เช่น โมเลกุลเบนซีน ซึ่งวิธีที่เราจะใช้ในการคำนวณหา Orbital Energy นั้นเราจะต้องทำการกำหนดฟังก์ชันคลื่นที่ใช้อธิบาย MO สำหรับ 
$\pi$ Electron ขึ้นมาก่อน ซึ่งเราสามารถใช้ผลรวมเชิงเส้นของ Atomic Orbitals ได้ เช่น สำหรับโมเลกุลเบนซีน เขียนได้ดังนี้ 

\begin{equation}
    \phi_{n} = \sum_{i=1}^{6} C_{i} \chi_{i} 
\end{equation}

โดยที่ $C_{i}$ คือ Molecular Orbital Coefficients และ $\chi$ คือ Basis Function คราวนี้เราสามารถใช้สมการ Eigenfunction

\begin{equation}    
    HC = \epsilon C
\end{equation}

\noindent ในการหา $\epsilon$ ซึ่งเป็นพลังงานของแต่ละออร์บิทัลได้ โดยที่ H คืออินทิกรัลของ Basis Function โดยหน้าตา H, C และ 
$\epsilon$ นั้นจริง ๆ แล้วก็คือ Square Matrix ดี ๆ นี่เอง โดยสามารถดูตัวอย่างของทั้งสามเมทริกซ์นี้สำหรับกรณีโมเลกุลเบนซีนได้ตามภาพที่ 1 
โดย $\alpha$ กับ $\beta$ นั้นก็คือ Coefficient ของแต่ AO แต่ละอันนั่นเอง เช่น อะตอมคาร์บอนตัวที่ 1 นั้นก็จะมี Interaction 
กับคาร์บอนที่ 2 กับ 6 ซึ่งการแก้สมการ Secular Equation นี้เราสามารถทำ Diagonalization ได้ โดยจัดรูปสมการเป็น%
\footnote{ต้องทำความเข้าใจกันก่อนว่าทฤษฎี H\"{u}ckel Model นั้นจะ Treat หรือสนใจเฉพาะ MO ของ $\pi$ Electron สำหรับโมเลกุล%
ที่เป็นแบบ $\pi$-conjugated เท่านั้น} 

\begin{equation}
    (H - \epsilon)C = 0
\end{equation}

หนึ่งในวิธีที่หลายคนมักจะนำมาใช้ในการทำ Diagonalization นั้นก็คือ Jacobi Method แต่ว่าวิธีนี้มีจุดอ่อนคือมันไม่ได้ทำการแยกตัวประกอบของ 
Secular Equation ออกเป็นเทอม ๆ จึงทำให้เราไม่มี Main-diagonal Block แล้ว Main-diagonal Block คืออะไร? ทำไมถึงสำคัญ?
ประเด็นก็คือการที่เราทำ Diagonalization นั้นมันจะมีวิธีบางอย่างที่สามารถจัดการเมทริกซ์ให้อยู่ในรูปที่เกิดจากการประกอบกันระหว่าง Diagonal 
Matrix หลาย ๆ อันได้และสมาชิกของเมทริกซ์ที่อยู่นอก Main-diagonal Block นั้นจะต้องเป็น 0 ด้วย เช่นให้ดูตามภาพที่ 2 ถ้าใครยังไม่เข้าใจ%
ให้ดูภาพที่ 3 จะได้เห็นภาพของ Diagonal Block ชัดขึ้น ซึ่งกลับมาที่ Jacobi Method ที่ไม่ได้ทำการแยก Block Diagonal Matrix 
ออกมาให้เรา ซึ่งนี่เป็นสาเหตุที่ทำให้ Symmetry ของโมเลกุลนั้นหายไประหว่างการทำ Diagonalization และทำให้ออร์บิทัลที่เป็นแบบ Degenerate 
(ออร์บิทัลที่มีพลังงานเท่ากัน) นั้นหายไปด้วย ซึ่งในความเป็นจริงโมเลกุลเบนซีนจะต้องมีบางออร์บิทัลที่มีพลังงานเท่ากัน ตามภาพที่ 4 
ดังนั้นสิ่งที่เราต้องการคือ Diagonalization Method ที่สามารถให้ Main-diagonal Block ที่มีให้ Degenerate MOs อย่างไรก็ตามในการ%
คำนวณทางเคมีควอนตัมนั้นถ้าหากเราใช้ทฤษฎีอื่น ๆ นั้นก็จะมีการนิยามและคำนวณหาพลังงาน MO (Eigenvalues) ที่แตกต่างกันไปและซับซ้อนมากขึ้น 
แต่หลัก ๆ แล้วก็จะต้องมีการทำ Diagonalization อยู่ดีครับ

%----------------------------------------
\section{แบบฝึกหัด}
%----------------------------------------
